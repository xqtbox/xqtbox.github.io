<!DOCTYPE html>
<html lang=zh>
<head>
    <meta charset="utf-8">
    
    <title>在TensorFlow中实现文本分类的CNN | 博客堂</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="注意：  本文翻译自WILDML的博客Implementing a CNN for Text Classification in TensorFlow 博客地址： http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/ github地址：https://github.com/de">
<meta name="keywords" content="自然语言处理,CNN,Tensorflow">
<meta property="og:type" content="article">
<meta property="og:title" content="在TensorFlow中实现文本分类的CNN">
<meta property="og:url" content="http://yoursite.com/2017/09/06/在TensorFlow中实现文本分类的CNN/index.html">
<meta property="og:site_name" content="博客堂">
<meta property="og:description" content="注意：  本文翻译自WILDML的博客Implementing a CNN for Text Classification in TensorFlow 博客地址： http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/ github地址：https://github.com/de">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/arabic-pyramid.jpg">
<meta property="og:updated_time" content="2018-01-23T07:54:34.645Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="在TensorFlow中实现文本分类的CNN">
<meta name="twitter:description" content="注意：  本文翻译自WILDML的博客Implementing a CNN for Text Classification in TensorFlow 博客地址： http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/ github地址：https://github.com/de">
<meta name="twitter:image" content="http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/arabic-pyramid.jpg">
    

    

    
        <link rel="icon" href="/css/images/favicon.ico" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    




</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">博客堂</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">主页</a>
                
                    <a class="main-nav-link" href="/archives">目录</a>
                
                    <a class="main-nav-link" href="/categories">分类</a>
                
                    <a class="main-nav-link" href="/tags">标签</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/avatar01.png" />
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">主页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">目录</a></td>
                
                    <td><a class="main-nav-link" href="/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/avatar01.png" />
            <h2 id="name">Qingtang</h2>
            <h3 id="title">Developer &amp; NLPer</h3>
            <span id="location"><i class="fa fa-map-marker"></i>HeFei, China</span>
            <a id="follow" target="_blank" href="https://github.com/xqtbox/">关注我</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                48
                <span>文章</span>
            </div>
            <div class="article-info-block">
                40
                <span>标签</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="http://github.com/xqtbox" target="_blank" title="github" class=tooltip>
                            <i class="fa fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://weibo.com/u/5890351342" target="_blank" title="weibo" class=tooltip>
                            <i class="fa fa-weibo"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="twitter" class=tooltip>
                            <i class="fa fa-twitter"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="http://blog.csdn.net/u012052268" target="_blank" title="pencil" class=tooltip>
                            <i class="fa fa-pencil"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="wechat" class=tooltip>
                            <i class="fa fa-wechat"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-在TensorFlow中实现文本分类的CNN" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            
	
		<img src="http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/arabic-pyramid.jpg" class="article-banner" />
	



        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            在TensorFlow中实现文本分类的CNN
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/06/在TensorFlow中实现文本分类的CNN/">
            <time datetime="2017-09-05T17:07:04.000Z" itemprop="datePublished">2017-09-06</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/自然语言处理/">自然语言处理</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/CNN/">CNN</a>, <a class="tag-link" href="/tags/Tensorflow/">Tensorflow</a>, <a class="tag-link" href="/tags/自然语言处理/">自然语言处理</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p><strong>注意</strong>：</p>
<ul>
<li>本文翻译自WILDML的博客Implementing a CNN for Text Classification in TensorFlow</li>
<li>博客地址： <a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/" target="_blank" rel="noopener">http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/</a></li>
<li>github地址：<a href="https://github.com/dennybritz/cnn-text-classification-tf" target="_blank" rel="noopener">https://github.com/dennybritz/cnn-text-classification-tf</a></li>
</ul>
<p>在这篇文章中，我们将实现一个类似于Kim Yoon的卷积神经网络语句分类模型。 本文提出的模型在一系列文本分类任务（如情绪分析）中实现了良好的分类性能，并已成为新的文本分类架构的标准基准。</p>
<a id="more"></a>
<p>我假设你已经熟悉了应用于NLP的卷积神经网络的基础知识。 如果没有，我建议先阅读NLP的理解卷积神经网络，以获得必要的背景。</p>
<h2 id="1-数据和预处理"><a href="#1-数据和预处理" class="headerlink" title="1 数据和预处理"></a>1 数据和预处理</h2><p>我们在这篇文章中使用的数据集是Rotten Tomatoes的<a href="http://www.cs.cornell.edu/people/pabo/movie-review-data/" target="_blank" rel="noopener">Movie Review数据</a>，也是原始文件中使用的数据集之一。 数据集包含10,662个实例审查句子，半正负半数。 数据集的大小约为20k。 请注意，由于这个数据集很小，我们很可能会使用强大的模型。 此外，数据集不附带官方列车/测试拆分，因此我们只需将10％的数据用作开发套件。 原始文件报告了对数据进行10倍交叉验证的结果。</p>
<p>我不会在这篇文章中介绍数据预处理代码，但是它可以在Github上使用，并执行以下操作：</p>
<ul>
<li>从原始数据文件中加载正负句子。</li>
<li>使用与原始论文相同的代码清理文本数据。</li>
<li>将每个句子加到最大句子长度，结果是59.我们将特殊的<pad>标记附加到所有其他句子，使其成为59个字。 填充句子相同的长度是有用的，因为它允许我们有效地批量我们的数据，因为批处理中的每个示例必须具有相同的长度。</pad></li>
<li>构建词汇索引，并将每个单词映射到0到18,765之间的整数（词汇大小）。 每个句子都成为整数向量。</li>
</ul>
<h2 id="2-模型"><a href="#2-模型" class="headerlink" title="2 模型"></a>2 模型</h2><p>我们将在这篇文章中建立的网络大致如下：<br><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-8.03.47-AM.png" alt="image"><br>第一层将单词嵌入到低维向量中。 下一层使用多个过滤器大小对嵌入的字矢量进行卷积。 例如，一次滑过3个，4个或5个字。 接下来，我们将卷积层的结果最大化为一个长的特征向量，添加退出正则化，并使用softmax层对结果进行分类。</p>
<p>因为这是一个教育文章，我决定从原始文件中简化模型：</p>
<ul>
<li>我们不会将预先训练的word2vec矢量用于我们的词嵌入。 相反，我们从头开始学习嵌入。</li>
<li>我们不会对权重向量执行L2规范约束。 （和从业者指南）对句子分类的卷积神经网络的敏感性分析发现，约束对最终结果几乎没有影响。</li>
<li>原始实验用两个输入数据通道 - 静态和非静态字矢量。 我们只使用一个通道。</li>
</ul>
<p>将这些扩展代码添加到这里是比较简单的（几十行代码）。 看看帖子结尾的练习。</p>
<p>让我们开始吧！</p>
<h2 id="3-实现"><a href="#3-实现" class="headerlink" title="3 实现"></a>3 实现</h2><p>为了允许各种超参数配置，我们将代码放入一个TextCNN类中，在init函数中生成模型图。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"> </span><br><span class="line">class TextCNN(object):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    A CNN for text classification.</span><br><span class="line">    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def __init__(</span><br><span class="line">      self, sequence_length, num_classes, vocab_size,</span><br><span class="line">      embedding_size, filter_sizes, num_filters):</span><br><span class="line">        # Implementation...</span><br></pre></td></tr></table></figure></p>
<p>要实例化类，我们传递以下参数：</p>
<ul>
<li>sequence_length - 我们的句子的长度。 请记住，我们填充所有句子的长度相同（59为我们的数据集）。</li>
<li>num_classes - 输出层中的类数，在我们的例子中为正（负）。</li>
<li>vocab_size - 我们的词汇量。 这需要定义我们的嵌入层的大小，它将具有[vocabulary_size，embedding_size]的形状。</li>
<li>embedding_size - 我们嵌入的维度。</li>
<li>filter_sizes - 我们想要卷积过滤器覆盖的字数。 我们将为此处指定的每个大小设置num_filters。 例如，[3,4,5]意味着我们将有一个过滤器，分别滑过3个，4个和5个字，总共有3 * num_filters过滤器。</li>
<li>num_filters - 每个过滤器大小的过滤器数量（见上文）。</li>
</ul>
<h3 id="3-1-输入占位符"><a href="#3-1-输入占位符" class="headerlink" title="3.1 输入占位符"></a>3.1 输入占位符</h3><p>我们首先定义我们传递给我们网络的输入数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Placeholders for input, output and dropout</span><br><span class="line">self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=&quot;input_x&quot;)</span><br><span class="line">self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=&quot;input_y&quot;)</span><br><span class="line">self.dropout_keep_prob = tf.placeholder(tf.float32, name=&quot;dropout_keep_prob&quot;)</span><br></pre></td></tr></table></figure></p>
<p>tf.placeholder创建一个占位符变量，当我们在火车或测试时间执行它时，我们馈送到网络。 第二个参数是输入张量的形状。 无意味着该维度的长度可以是任何东西。 在我们的情况下，第一个维度是批量大小，并且使用“无”允许网络处理任意大小的批次。</p>
<p>将神经元保留在丢失层中的概率也是网络的输入，因为我们仅在训练期间启用退出。 我们在评估模型时禁用它（稍后再说）。</p>
<h3 id="3-2-向量层"><a href="#3-2-向量层" class="headerlink" title="3.2 向量层"></a>3.2 向量层</h3><p>我们定义的第一层是嵌入层，它将词汇词索引映射到低维向量表示中。 它本质上是一个从数据中学习的查找表。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">with tf.device(&apos;/cpu:0&apos;), tf.name_scope(&quot;embedding&quot;):</span><br><span class="line">    W = tf.Variable(</span><br><span class="line">        tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),</span><br><span class="line">        name=&quot;W&quot;)</span><br><span class="line">    self.embedded_chars = tf.nn.embedding_lookup(W, self.input_x)</span><br><span class="line">    self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)</span><br></pre></td></tr></table></figure></p>
<p>我们在这里使用了几个新功能，让我们来看看：</p>
<ul>
<li>tf.device（“/ cpu：0”）强制在CPU上执行操作。 默认情况下，TensorFlow将尝试将操作放在GPU上（如果有的话）可用，但是嵌入式实现当前没有GPU支持，并且如果放置在GPU上则会抛出错误。</li>
<li>tf.name_scope创建一个名称范围，名称为“embedding”。 范围将所有操作添加到名为“嵌入”的顶级节点中，以便在TensorBoard中可视化您的网络时获得良好的层次结构。</li>
</ul>
<p>W是我们在训练中学习的嵌入矩阵。 我们使用随机均匀分布来初始化它。 tf.nn.embedding_lookup创建实际的嵌入操作。 嵌入操作的结果是形状为[None，sequence_length，embedding_size]的三维张量。</p>
<p>TensorFlow的卷积conv2d操作期望具有对应于批次，宽度，高度和通道的尺寸的四维张量。 我们嵌入的结果不包含通道尺寸，所以我们手动添加它们，留下一层形状[None，sequence_length，embedding_size，1]。</p>
<h3 id="3-3-卷积层和池化层"><a href="#3-3-卷积层和池化层" class="headerlink" title="3.3 卷积层和池化层"></a>3.3 卷积层和池化层</h3><p>现在我们已经准备好构建卷积层，然后再进行最大化。 请记住，我们使用不同大小的过滤器。 因为每个卷积产生不同形状的张量，我们需要迭代它们，为它们中的每一个创建一个层，然后将结果合并成一个大的特征向量。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">pooled_outputs = []</span><br><span class="line">for i, filter_size in enumerate(filter_sizes):</span><br><span class="line">    with tf.name_scope(&quot;conv-maxpool-%s&quot; % filter_size):</span><br><span class="line">        # Convolution Layer</span><br><span class="line">        filter_shape = [filter_size, embedding_size, 1, num_filters]</span><br><span class="line">        W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=&quot;W&quot;)</span><br><span class="line">        b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=&quot;b&quot;)</span><br><span class="line">        conv = tf.nn.conv2d(</span><br><span class="line">            self.embedded_chars_expanded,</span><br><span class="line">            W,</span><br><span class="line">            strides=[1, 1, 1, 1],</span><br><span class="line">            padding=&quot;VALID&quot;,</span><br><span class="line">            name=&quot;conv&quot;)</span><br><span class="line">        # Apply nonlinearity</span><br><span class="line">        h = tf.nn.relu(tf.nn.bias_add(conv, b), name=&quot;relu&quot;)</span><br><span class="line">        # Max-pooling over the outputs</span><br><span class="line">        pooled = tf.nn.max_pool(</span><br><span class="line">            h,</span><br><span class="line">            ksize=[1, sequence_length - filter_size + 1, 1, 1],</span><br><span class="line">            strides=[1, 1, 1, 1],</span><br><span class="line">            padding=&apos;VALID&apos;,</span><br><span class="line">            name=&quot;pool&quot;)</span><br><span class="line">        pooled_outputs.append(pooled)</span><br><span class="line"> </span><br><span class="line"># Combine all the pooled features</span><br><span class="line">num_filters_total = num_filters * len(filter_sizes)</span><br><span class="line">self.h_pool = tf.concat(3, pooled_outputs)</span><br><span class="line">self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])</span><br></pre></td></tr></table></figure></p>
<p>这里，W是我们的滤波器矩阵，h是将非线性应用于卷积输出的结果。 每个过滤器在整个嵌入中滑过，但是它涵盖的字数有所不同。 “VALID”填充意味着我们将过滤器滑过我们的句子而不填充边缘，执行一个窄的卷积，给出一个形状[1，sequence_length - filter_size + 1,1,1]的输出。 在特定过滤器大小的输出上执行最大化池将留下一张张量[batch_size，1，num_filters]。 这本质上是一个特征向量，其中最后一个维度对应于我们的特征。 一旦我们从每个过滤器大小得到所有的汇集输出张量，我们将它们组合成一个长形特征向量[batch_size，num_filters_total]。 在tf.reshape中使用-1可以告诉TensorFlow在可能的情况下平坦化维度。</p>
<p>花一些时间，尝试了解每个操作的输出形状。 您还可以参考NLP的理解卷积神经网络来获得一些直觉。 可视化TensorBoard中的操作也可以帮助（对于特定的过滤器大小3,4和5）</p>
<p><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-10-at-10.13.50-AM1-1024x525.png" alt="image"></p>
<p><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-10-at-10.22.29-AM.png" alt="image"></p>
<h3 id="3-4-Dropout-层"><a href="#3-4-Dropout-层" class="headerlink" title="3.4 Dropout 层"></a>3.4 Dropout 层</h3><p>花一些时间，尝试了解每个操作的输出形状。 您还可以参考NLP的理解卷积神经网络来获得一些直觉。 可视化TensorBoard中的操作也可以帮助（对于特定的过滤器大小3,4和5）……</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Add dropout</span><br><span class="line">with tf.name_scope(&quot;dropout&quot;):</span><br><span class="line">    self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)</span><br></pre></td></tr></table></figure>
<h3 id="3-5-得分和预测"><a href="#3-5-得分和预测" class="headerlink" title="3.5 得分和预测"></a>3.5 得分和预测</h3><p>使用max-pooling中的特征向量（使用退出），我们可以通过执行矩阵乘法并选择具有最高分数的类来生成预测。 我们还可以应用softmax函数将原始分数转换为归一化概率，但这不会改变我们的最终预测。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with tf.name_scope(&quot;output&quot;):</span><br><span class="line">    W = tf.Variable(tf.truncated_normal([num_filters_total, num_classes], stddev=0.1), name=&quot;W&quot;)</span><br><span class="line">    b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=&quot;b&quot;)</span><br><span class="line">    self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=&quot;scores&quot;)</span><br><span class="line">    self.predictions = tf.argmax(self.scores, 1, name=&quot;predictions&quot;)</span><br></pre></td></tr></table></figure>
<p>这里，tf.nn.xw_plus_b是执行Wx + b矩阵乘法的便利包装器。</p>
<h3 id="3-6-loss-和-Accuracy"><a href="#3-6-loss-和-Accuracy" class="headerlink" title="3.6 loss 和 Accuracy"></a>3.6 loss 和 Accuracy</h3><p>使用我们的分数我们可以定义损失函数。 损失是我们网络造成的错误的衡量标准，我们的目标是尽量减少网络的误差。 分类问题的标准损失函数是交叉熵损失。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Calculate mean cross-entropy loss</span><br><span class="line">with tf.name_scope(&quot;loss&quot;):</span><br><span class="line">    losses = tf.nn.softmax_cross_entropy_with_logits(self.scores, self.input_y)</span><br><span class="line">    self.loss = tf.reduce_mean(losses)</span><br></pre></td></tr></table></figure>
<p>这里，tf.nn.softmax_cross_entropy_with_logits是一个方便的函数，计算每个类的交叉熵损失，给定我们的分数和正确的输入标签。 然后我们把损失的平均值。</p>
<p>我们也可以使用这个总和，但这比较难以比较不同批量大小和列车/开发数据的损失。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Calculate Accuracy</span><br><span class="line">with tf.name_scope(&quot;accuracy&quot;):</span><br><span class="line">    correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))</span><br><span class="line">    self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, &quot;float&quot;), name=&quot;accuracy&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="3-7-可视化网络"><a href="#3-7-可视化网络" class="headerlink" title="3.7 可视化网络"></a>3.7 可视化网络</h3><p>就这样，我们完成了我们的网络定义。 完整的代码网络定义代码在这里可用。 为了获得大图，我们还可以在TensorBoard中可视化网络：<img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-10-at-10.25.46-AM.png" alt="image"></p>
<h2 id="4-训练过程"><a href="#4-训练过程" class="headerlink" title="4 训练过程"></a>4 训练过程</h2><p>在我们为网络定义培训程序之前，我们需要了解一些关于TensorFlow如何使用会话和图形的基础知识。 如果您已经熟悉这些概念，请随时跳过本节。</p>
<p>在TensorFlow中，会话是您正在执行图形操作的环境，它包含有关变量和队列的状态。 每个会话都在单个图形上运行。 如果在创建变量和操作时未明确使用会话，则使用TensorFlow创建的当前默认会话。 您可以通过执行session.as_default（）块中的命令来更改默认会话（见下文）。</p>
<p>图形包含操作和张量。 您可以在程序中使用多个图形，但大多数程序只需要一个图形。 您可以在多个会话中使用相同的图表，但在一个会话中不能使用多个图表。 TensorFlow始终创建一个默认图形，但您也可以手动创建一个图形，并将其设置为新的默认图像，如下所示。 显式创建会话和图表可确保在不再需要资源时正确释放资源。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">with tf.Graph().as_default():</span><br><span class="line">    session_conf = tf.ConfigProto(</span><br><span class="line">      allow_soft_placement=FLAGS.allow_soft_placement,</span><br><span class="line">      log_device_placement=FLAGS.log_device_placement)</span><br><span class="line">    sess = tf.Session(config=session_conf)</span><br><span class="line">    with sess.as_default():</span><br><span class="line">        # Code that operates on the default graph and session comes here...</span><br></pre></td></tr></table></figure></p>
<p>allow_soft_placement设置允许TensorFlow在首选设备不存在的情况下实现特定操作的设备上回退。 例如，如果我们的代码在GPU上执行操作，并且我们在没有GPU的机器上运行代码，则不使用allow_soft_placement将导致错误。 如果设置了log_device_placement，TensorFlow会登录哪些设备（CPU或GPU）进行操作。 这对调试非常有用。 标记是我们程序的命令行参数。</p>
<h3 id="4-1-实例化CNN并尽可能减少损失"><a href="#4-1-实例化CNN并尽可能减少损失" class="headerlink" title="4.1 实例化CNN并尽可能减少损失"></a>4.1 实例化CNN并尽可能减少损失</h3><p>当我们实例化我们的TextCNN模型时，所有定义的变量和操作将被放置在上面创建的默认图形和会话中。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cnn = TextCNN(</span><br><span class="line">    sequence_length=x_train.shape[1],</span><br><span class="line">    num_classes=2,</span><br><span class="line">    vocab_size=len(vocabulary),</span><br><span class="line">    embedding_size=FLAGS.embedding_dim,</span><br><span class="line">    filter_sizes=map(int, FLAGS.filter_sizes.split(&quot;,&quot;)),</span><br><span class="line">    num_filters=FLAGS.num_filters)</span><br></pre></td></tr></table></figure></p>
<p>接下来，我们定义如何优化网络损耗功能。 TensorFlow有几个内置优化器。 我们正在使用Adam优化器。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">global_step = tf.Variable(0, name=&quot;global_step&quot;, trainable=False)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(1e-4)</span><br><span class="line">grads_and_vars = optimizer.compute_gradients(cnn.loss)</span><br><span class="line">train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)</span><br></pre></td></tr></table></figure></p>
<p>在这里，train_op这里是一个新创建的操作，我们可以运行它来对我们的参数执行渐变更新。 train_op的每次执行都是一个训练步骤。 TensorFlow自动计算哪些变量是“可训练的”并计算它们的梯度。 通过定义一个global_step变量并将其传递给优化器，我们允许TensorFlow处理对我们的培训步骤的计数。 每次执行train_op时，全局步骤将自动递增1。</p>
<h3 id="4-2-Summaries-摘要"><a href="#4-2-Summaries-摘要" class="headerlink" title="4.2 Summaries 摘要"></a>4.2 Summaries 摘要</h3><p>TensorFlow有一个Summaries，可以让您在培训和评估过程中跟踪和查看各种数量。 例如，您可能想要跟踪您的损失和准确性随时间的变化。 您还可以跟踪更复杂的数量，例如图层激活的直方图。 汇总是序列化的对象，它们使用SummaryWriter写入磁盘。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># Output directory for models and summaries</span><br><span class="line">timestamp = str(int(time.time()))</span><br><span class="line">out_dir = os.path.abspath(os.path.join(os.path.curdir, &quot;runs&quot;, timestamp))</span><br><span class="line">print(&quot;Writing to &#123;&#125;\n&quot;.format(out_dir))</span><br><span class="line"> </span><br><span class="line"># Summaries for loss and accuracy</span><br><span class="line">loss_summary = tf.scalar_summary(&quot;loss&quot;, cnn.loss)</span><br><span class="line">acc_summary = tf.scalar_summary(&quot;accuracy&quot;, cnn.accuracy)</span><br><span class="line"> </span><br><span class="line"># Train Summaries</span><br><span class="line">train_summary_op = tf.merge_summary([loss_summary, acc_summary])</span><br><span class="line">train_summary_dir = os.path.join(out_dir, &quot;summaries&quot;, &quot;train&quot;)</span><br><span class="line">train_summary_writer = tf.train.SummaryWriter(train_summary_dir, sess.graph_def)</span><br><span class="line"> </span><br><span class="line"># Dev summaries</span><br><span class="line">dev_summary_op = tf.merge_summary([loss_summary, acc_summary])</span><br><span class="line">dev_summary_dir = os.path.join(out_dir, &quot;summaries&quot;, &quot;dev&quot;)</span><br><span class="line">dev_summary_writer = tf.train.SummaryWriter(dev_summary_dir, sess.graph_def)</span><br></pre></td></tr></table></figure>
<p>在这里，我们分别跟踪培训和评估的总结。 在我们的情况下，这些数量是相同的，但您可能只有在培训期间跟踪的数量（如参数更新值）。 tf.merge_summary是将多个摘要操作合并到可以执行的单个操作中的便利函数。</p>
<h3 id="4-3-Checkpointing-检查点"><a href="#4-3-Checkpointing-检查点" class="headerlink" title="4.3 Checkpointing 检查点"></a>4.3 Checkpointing 检查点</h3><p>您通常想要使用的另一个TensorFlow功能是检查点 - 保存模型的参数以便稍后恢复。 检查点可用于稍后继续训练，或使用提前停止选择最佳参数设置。 使用Saver对象创建检查点。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Checkpointing</span><br><span class="line">checkpoint_dir = os.path.abspath(os.path.join(out_dir, &quot;checkpoints&quot;))</span><br><span class="line">checkpoint_prefix = os.path.join(checkpoint_dir, &quot;model&quot;)</span><br><span class="line"># Tensorflow assumes this directory already exists so we need to create it</span><br><span class="line">if not os.path.exists(checkpoint_dir):</span><br><span class="line">    os.makedirs(checkpoint_dir)</span><br><span class="line">saver = tf.train.Saver(tf.all_variables())</span><br></pre></td></tr></table></figure>
<h3 id="4-4-Initializing-the-variables初始化变量"><a href="#4-4-Initializing-the-variables初始化变量" class="headerlink" title="4.4 Initializing the variables初始化变量"></a>4.4 Initializing the variables初始化变量</h3><p>在我们可以训练我们的模型之前，我们还需要在图中初始化变量。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess.run(tf.initialize_all_variables())</span><br></pre></td></tr></table></figure></p>
<p>initialize_all_variables函数是一个方便的函数，运行我们为变量定义的所有初始化器。 您也可以手动调用变量的初始值。 如果您希望使用预先训练的值初始化嵌入，这很有用。</p>
<h3 id="4-5Defining-a-single-training-step定义单一培训步骤"><a href="#4-5Defining-a-single-training-step定义单一培训步骤" class="headerlink" title="4.5Defining a single training step定义单一培训步骤"></a>4.5Defining a single training step定义单一培训步骤</h3><p>现在我们来定义一个单一的训练步骤的功能，评估一批数据上的模型和更新模型参数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def train_step(x_batch, y_batch):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    A single training step</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    feed_dict = &#123;</span><br><span class="line">      cnn.input_x: x_batch,</span><br><span class="line">      cnn.input_y: y_batch,</span><br><span class="line">      cnn.dropout_keep_prob: FLAGS.dropout_keep_prob</span><br><span class="line">    &#125;</span><br><span class="line">    _, step, summaries, loss, accuracy = sess.run(</span><br><span class="line">        [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],</span><br><span class="line">        feed_dict)</span><br><span class="line">    time_str = datetime.datetime.now().isoformat()</span><br><span class="line">    print(&quot;&#123;&#125;: step &#123;&#125;, loss &#123;:g&#125;, acc &#123;:g&#125;&quot;.format(time_str, step, loss, accuracy))</span><br><span class="line">    train_summary_writer.add_summary(summaries, step)</span><br></pre></td></tr></table></figure></p>
<p>feed_dict包含我们传递到我们网络的占位符节点的数据。您必须为所有占位符节点提供值，否则TensorFlow将抛出错误。使用输入数据的另一种方法是使用队列，但这超出了这篇文章的范围。</p>
<p>接下来，我们使用session.run执行我们的train_op，它返回我们要求它进行评估的所有操作的值。请注意，train_op什么都不返回，它只是更新我们网络的参数。最后，我们打印当前培训批次的损失和准确性，并将总结保存到磁盘。请注意，如果批量大小，培训批次的损失和准确性可能会有很大差异。而且因为我们使用辍学，您的培训指标可能开始比您的评估指标更差。</p>
<p>我们编写一个类似的函数来评估任意数据集的丢失和准确性，例如验证集或整个训练集。本质上这个功能与上述相同，但没有训练操作。它也禁用退学。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def dev_step(x_batch, y_batch, writer=None):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Evaluates model on a dev set</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    feed_dict = &#123;</span><br><span class="line">      cnn.input_x: x_batch,</span><br><span class="line">      cnn.input_y: y_batch,</span><br><span class="line">      cnn.dropout_keep_prob: 1.0</span><br><span class="line">    &#125;</span><br><span class="line">    step, summaries, loss, accuracy = sess.run(</span><br><span class="line">        [global_step, dev_summary_op, cnn.loss, cnn.accuracy],</span><br><span class="line">        feed_dict)</span><br><span class="line">    time_str = datetime.datetime.now().isoformat()</span><br><span class="line">    print(&quot;&#123;&#125;: step &#123;&#125;, loss &#123;:g&#125;, acc &#123;:g&#125;&quot;.format(time_str, step, loss, accuracy))</span><br><span class="line">    if writer:</span><br><span class="line">        writer.add_summary(summaries, step)</span><br></pre></td></tr></table></figure></p>
<h3 id="4-6-Training-loop训练循环"><a href="#4-6-Training-loop训练循环" class="headerlink" title="4.6 Training loop训练循环"></a>4.6 Training loop训练循环</h3><p>最后，我们准备好编写我们的训练循环。 我们迭代我们的数据批次，为每个批次调用train_step函数，并偶尔评估和检查我们的模型：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Generate batches</span><br><span class="line">batches = data_helpers.batch_iter(</span><br><span class="line">    zip(x_train, y_train), FLAGS.batch_size, FLAGS.num_epochs)</span><br><span class="line"># Training loop. For each batch...</span><br><span class="line">for batch in batches:</span><br><span class="line">    x_batch, y_batch = zip(*batch)</span><br><span class="line">    train_step(x_batch, y_batch)</span><br><span class="line">    current_step = tf.train.global_step(sess, global_step)</span><br><span class="line">    if current_step % FLAGS.evaluate_every == 0:</span><br><span class="line">        print(&quot;\nEvaluation:&quot;)</span><br><span class="line">        dev_step(x_dev, y_dev, writer=dev_summary_writer)</span><br><span class="line">        print(&quot;&quot;)</span><br><span class="line">    if current_step % FLAGS.checkpoint_every == 0:</span><br><span class="line">        path = saver.save(sess, checkpoint_prefix, global_step=current_step)</span><br><span class="line">        print(&quot;Saved model checkpoint to &#123;&#125;\n&quot;.format(path))</span><br></pre></td></tr></table></figure></p>
<p>这里，batch_iter是一个我写的批处理数据的帮助函数，而tf.train.global_step是返回global_step值的便利函数。 培训的完整代码也在这里提供。</p>
<h2 id="5-Visualizing-Results-in-TensorBoard-在TensorBoard中可视化结果"><a href="#5-Visualizing-Results-in-TensorBoard-在TensorBoard中可视化结果" class="headerlink" title="5 Visualizing Results in TensorBoard 在TensorBoard中可视化结果"></a>5 Visualizing Results in TensorBoard 在TensorBoard中可视化结果</h2><p>我们的训练脚本将摘要写入输出目录，并通过将TensorBoard指向该目录，我们可以将图形和我们创建的摘要可视化。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir /PATH_TO_CODE/runs/1449760558/summaries/</span><br></pre></td></tr></table></figure></p>
<p>使用默认参数（128维嵌入，过滤器尺寸为3，4和5，每个过滤器尺寸为0.5和128个过滤器）的运行训练过程导致以下损失和精度图（蓝色是训练数据，红色为10％ 开发数据）。</p>
<p><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-11-at-6.29.14-AM-768x260.png" alt="image"></p>
<p><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-11-at-6.27.48-AM-768x262.png" alt="image"></p>
<p>有几件事情脱颖而出：</p>
<ul>
<li>我们的培训指标不顺利，因为我们使用小批量大小。 如果我们使用较大的批次（或在整个训练集上评估），我们将获得更平滑的蓝线。</li>
<li>因为开发者的准确性显着低于训练准确度，我们的网络似乎超过了训练数据，这表明我们需要更多的数据（MR数据集非常小），更强的正则化或更少的模型参数。 例如，我尝试在最后一层添加额外的L2惩罚权重，并能够将准确度提高到76％，接近于原始报告。</li>
<li>培训损失和准确性开始大大低于开发商指标，因为应用了退出。</li>
</ul>
<p>您可以玩代码，并尝试运行具有各种参数配置的模型。 Github提供了代码和说明。</p>
<h2 id="6-Extensions-and-Exercises扩展和练习"><a href="#6-Extensions-and-Exercises扩展和练习" class="headerlink" title="6 Extensions and Exercises扩展和练习"></a>6 Extensions and Exercises扩展和练习</h2><p>以下是一些有用的练习，可以提高模型的性能：</p>
<ul>
<li>使用预先训练的word2vec向量初始化嵌入。 为了使这项工作，您需要使用300维嵌入，并用预先训练的值初始化它们。</li>
<li>限制最后一层权重向量的L2范数，就像原始的纸张一样。 您可以通过定义一个新的操作，在每个培训步骤之后更新权重值。</li>
<li>将L2正规化添加到网络以防止过度配对，同时也提高辍学率。 （Github上的代码已经包括L2正则化，但默认情况下禁用）</li>
<li>添加重量更新和图层操作的直方图摘要，并在TensorBoard中进行可视化。</li>
</ul>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="http://yoursite.com/2017/09/06/在TensorFlow中实现文本分类的CNN/" data-id="cjcrdq43h002rhajet34kp8fs" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="http://yoursite.com/2017/09/06/在TensorFlow中实现文本分类的CNN/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="http://yoursite.com/2017/09/06/在TensorFlow中实现文本分类的CNN/">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2017/09/19/深度学习 自然语言处理 怎么获得数据集 中文语料集？/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    深度学习 自然语言处理 怎么获得数据集 中文语料集？
                
            </div>
        </a>
    
    
        <a href="/2017/09/04/零基础学习GitHub桌面版-5 github的使用技巧/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">零基础学习GitHub桌面版-5 github的使用技巧</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
</section>
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/01/11/hello-world/" class="thumbnail">
    
    
        <span style="background-image:url(http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/salt-lake.jpg)" alt="Hello World" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2018/01/11/hello-world/" class="title">Hello World</a></p>
                            <p class="item-date"><time datetime="2018-01-11T03:11:11.000Z" itemprop="datePublished">2018-01-11</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2017/11/28/coursera-斯坦福-机器学习-吴恩达-第3周笔记-逻辑回归/" class="thumbnail">
    
    
        <span style="background-image:url(http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/niagara.jpg)" alt="coursera-斯坦福-机器学习-吴恩达-第3周笔记-逻辑回归" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/机器学习/">机器学习</a></p>
                            <p class="item-title"><a href="/2017/11/28/coursera-斯坦福-机器学习-吴恩达-第3周笔记-逻辑回归/" class="title">coursera-斯坦福-机器学习-吴恩达-第3周笔记-逻辑回归</a></p>
                            <p class="item-date"><time datetime="2017-11-28T03:01:34.000Z" itemprop="datePublished">2017-11-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2017/11/21/coursera-斯坦福-机器学习-吴恩达-第2周笔记/" class="thumbnail">
    
    
        <span style="background-image:url(http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/little-girl.jpg)" alt="coursera-斯坦福-机器学习-吴恩达-第2周笔记" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/机器学习/">机器学习</a></p>
                            <p class="item-title"><a href="/2017/11/21/coursera-斯坦福-机器学习-吴恩达-第2周笔记/" class="title">coursera-斯坦福-机器学习-吴恩达-第2周笔记</a></p>
                            <p class="item-date"><time datetime="2017-11-21T13:01:34.000Z" itemprop="datePublished">2017-11-21</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2017/11/16/coursera-斯坦福-机器学习-吴恩达-第1周笔记/" class="thumbnail">
    
    
        <span style="background-image:url(http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/music2.jpg)" alt="coursera-斯坦福-机器学习-吴恩达-第1周笔记" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/机器学习/">机器学习</a></p>
                            <p class="item-title"><a href="/2017/11/16/coursera-斯坦福-机器学习-吴恩达-第1周笔记/" class="title">coursera-斯坦福-机器学习-吴恩达-第1周笔记</a></p>
                            <p class="item-date"><time datetime="2017-11-16T13:02:34.000Z" itemprop="datePublished">2017-11-16</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2017/09/19/深度学习 自然语言处理 怎么获得数据集 中文语料集？/" class="thumbnail">
    
    
        <span style="background-image:url(http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/guitarist.jpg)" alt="深度学习 自然语言处理 怎么获得数据集 中文语料集？" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/自然语言处理/">自然语言处理</a></p>
                            <p class="item-title"><a href="/2017/09/19/深度学习 自然语言处理 怎么获得数据集 中文语料集？/" class="title">深度学习 自然语言处理 怎么获得数据集 中文语料集？</a></p>
                            <p class="item-date"><time datetime="2017-09-19T12:07:04.000Z" itemprop="datePublished">2017-09-19</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/自然语言处理/">自然语言处理</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/驱动开发/">驱动开发</a><span class="category-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">3</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Anaconda/">Anaconda</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/">CNN</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DevOps/">DevOps</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DriverSttudio3-2/">DriverSttudio3.2</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Editplus/">Editplus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GBK/">GBK</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/">Git</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GitHub/">GitHub</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keras/">Keras</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Oracle/">Oracle</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pycharm/">Pycharm</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">20</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/">RNN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorboard/">Tensorboard</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/">Tensorflow</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/USB/">USB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/UTF-8/">UTF-8</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/coursera/">coursera</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ddk/">ddk</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/eclipse/">eclipse</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jieba/">jieba</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/myeclipse/">myeclipse</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrapy/">scrapy</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/win7/">win7</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/word2vec/">word2vec</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分词/">分词</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/学习路线/">学习路线</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/报错/">报错</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文件操作/">文件操作</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/汽车之家/">汽车之家</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编码/">编码</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/自然语言处理/">自然语言处理</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/运维/">运维</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面向对象/">面向对象</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/驱动程序/">驱动程序</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Anaconda/" style="font-size: 12.5px;">Anaconda</a> <a href="/tags/CNN/" style="font-size: 11.25px;">CNN</a> <a href="/tags/DevOps/" style="font-size: 10px;">DevOps</a> <a href="/tags/DriverSttudio3-2/" style="font-size: 10px;">DriverSttudio3.2</a> <a href="/tags/Editplus/" style="font-size: 10px;">Editplus</a> <a href="/tags/GBK/" style="font-size: 11.25px;">GBK</a> <a href="/tags/Git/" style="font-size: 17.5px;">Git</a> <a href="/tags/GitHub/" style="font-size: 17.5px;">GitHub</a> <a href="/tags/Java/" style="font-size: 17.5px;">Java</a> <a href="/tags/Keras/" style="font-size: 10px;">Keras</a> <a href="/tags/Linux/" style="font-size: 13.75px;">Linux</a> <a href="/tags/Oracle/" style="font-size: 10px;">Oracle</a> <a href="/tags/Pycharm/" style="font-size: 12.5px;">Pycharm</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/Tensorboard/" style="font-size: 10px;">Tensorboard</a> <a href="/tags/Tensorflow/" style="font-size: 13.75px;">Tensorflow</a> <a href="/tags/USB/" style="font-size: 10px;">USB</a> <a href="/tags/UTF-8/" style="font-size: 11.25px;">UTF-8</a> <a href="/tags/coursera/" style="font-size: 12.5px;">coursera</a> <a href="/tags/ddk/" style="font-size: 10px;">ddk</a> <a href="/tags/eclipse/" style="font-size: 13.75px;">eclipse</a> <a href="/tags/jieba/" style="font-size: 10px;">jieba</a> <a href="/tags/myeclipse/" style="font-size: 12.5px;">myeclipse</a> <a href="/tags/scrapy/" style="font-size: 15px;">scrapy</a> <a href="/tags/win7/" style="font-size: 10px;">win7</a> <a href="/tags/word2vec/" style="font-size: 10px;">word2vec</a> <a href="/tags/分词/" style="font-size: 10px;">分词</a> <a href="/tags/学习路线/" style="font-size: 11.25px;">学习路线</a> <a href="/tags/报错/" style="font-size: 16.25px;">报错</a> <a href="/tags/文件操作/" style="font-size: 10px;">文件操作</a> <a href="/tags/机器学习/" style="font-size: 12.5px;">机器学习</a> <a href="/tags/汽车之家/" style="font-size: 11.25px;">汽车之家</a> <a href="/tags/深度学习/" style="font-size: 16.25px;">深度学习</a> <a href="/tags/爬虫/" style="font-size: 18.75px;">爬虫</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/自然语言处理/" style="font-size: 16.25px;">自然语言处理</a> <a href="/tags/运维/" style="font-size: 10px;">运维</a> <a href="/tags/面向对象/" style="font-size: 10px;">面向对象</a> <a href="/tags/驱动程序/" style="font-size: 10px;">驱动程序</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2018 Qingtang<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>



        
    
    <script>
    var disqus_config = function () {
        
            this.page.url = 'http://yoursite.com/2017/09/06/在TensorFlow中实现文本分类的CNN/';
        
        this.page.identifier = '在TensorFlow中实现文本分类的CNN';
    };
    (function() { 
        var d = document, s = d.createElement('script');  
        s.src = '//' + 'xqtbox' + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>