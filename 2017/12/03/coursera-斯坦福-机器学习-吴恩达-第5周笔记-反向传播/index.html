<!DOCTYPE html>
<html lang=zh>
<head>
    <meta charset="utf-8">
    
    <title>coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播 | 博客堂</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="1代价函数and反向传播1.1代价函数首先定义一些我们需要使用的变量：  L =网络中的总层数 $s_l$ =第l层中的单位数量（不包括偏差单位） K =输出单元/类的数量  首先，回想一下“逻辑回归”正则化的成本函数是：">
<meta name="keywords" content="机器学习,coursera">
<meta property="og:type" content="article">
<meta property="og:title" content="coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播">
<meta property="og:url" content="http://yoursite.com/2017/12/03/coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播/index.html">
<meta property="og:site_name" content="博客堂">
<meta property="og:description" content="1代价函数and反向传播1.1代价函数首先定义一些我们需要使用的变量：  L =网络中的总层数 $s_l$ =第l层中的单位数量（不包括偏差单位） K =输出单元/类的数量  首先，回想一下“逻辑回归”正则化的成本函数是：">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/music1.jpg">
<meta property="og:updated_time" content="2018-01-23T08:40:04.657Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播">
<meta name="twitter:description" content="1代价函数and反向传播1.1代价函数首先定义一些我们需要使用的变量：  L =网络中的总层数 $s_l$ =第l层中的单位数量（不包括偏差单位） K =输出单元/类的数量  首先，回想一下“逻辑回归”正则化的成本函数是：">
<meta name="twitter:image" content="http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/music1.jpg">
    

    

    
        <link rel="icon" href="/css/images/favicon.ico" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    




</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">博客堂</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">主页</a>
                
                    <a class="main-nav-link" href="/archives">归档</a>
                
                    <a class="main-nav-link" href="/categories">分类</a>
                
                    <a class="main-nav-link" href="/tags">标签</a>
                
                    <a class="main-nav-link" href="/about">关于</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/avatar01.png" />
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">主页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/avatar01.png" />
            <h2 id="name">Qingtang</h2>
            <h3 id="title">Developer &amp; NLPer</h3>
            <span id="location"><i class="fa fa-map-marker"></i>HeFei, China</span>
            <a id="follow" target="_blank" href="https://github.com/xqtbox/">关注我</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                63
                <span>文章</span>
            </div>
            <div class="article-info-block">
                41
                <span>标签</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="http://github.com/xqtbox" target="_blank" title="github" class=tooltip>
                            <i class="fa fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://weibo.com/u/5890351342" target="_blank" title="weibo" class=tooltip>
                            <i class="fa fa-weibo"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="twitter" class=tooltip>
                            <i class="fa fa-twitter"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="http://blog.csdn.net/u012052268" target="_blank" title="pencil" class=tooltip>
                            <i class="fa fa-pencil"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="wechat" class=tooltip>
                            <i class="fa fa-wechat"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            
	
		<img src="http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/music1.jpg" class="article-banner" />
	



        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/12/03/coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播/">
            <time datetime="2017-12-03T02:51:34.000Z" itemprop="datePublished">2017-12-03</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/coursera/">coursera</a>, <a class="tag-link" href="/tags/机器学习/">机器学习</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h2 id="1代价函数and反向传播"><a href="#1代价函数and反向传播" class="headerlink" title="1代价函数and反向传播"></a>1代价函数and反向传播</h2><h3 id="1-1代价函数"><a href="#1-1代价函数" class="headerlink" title="1.1代价函数"></a>1.1代价函数</h3><p>首先定义一些我们需要使用的变量：</p>
<ul>
<li>L =网络中的总层数</li>
<li>$s_l$ =第l层中的单位数量（不包括偏差单位）</li>
<li>K =输出单元/类的数量</li>
</ul>
<p>首先，回想一下“逻辑回归”正则化的成本函数是：</p>
<a id="more"></a>
<p>$J(\theta) = - \frac{1}{m} \sum<em>{i=1}^m [ y^{(i)}\ \log (h</em>\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h<em>\theta(x^{(i)}))] + \frac{\lambda}{2m}\sum</em>{j=1}^n \theta_j^2$</p>
<p>再回想一下，在神经网络中，我们可能有许多输出节点。我们把 $h_\Theta(x)_k$表示为导致第k个输出的假设。我们的神经网络的成本函数将会是我们用于逻辑回归的一个综合泛化。神经网络的代价函数为：</p>
<p>$ J(\Theta) = - \frac{1}{m} \sum<em>{i=1}^m \sum</em>{k=1}^K \left[y^{(i)}<em>k \log ((h</em>\Theta (x^{(i)}))_k) + (1 - y^{(i)}<em>k)\log (1 - (h</em>\Theta(x^{(i)}))<em>k)\right] + \frac{\lambda}{2m}\sum</em>{l=1}^{L-1} \sum_{i=1}^{s<em>l} \sum</em>{j=1}^{s<em>{l+1}} ( \Theta</em>{j,i}^{(l)})^2$</p>
<p>这个式子看着复杂，但其实并不难理解：我们只是添加了几个嵌套的求和，来解释我们的多个输出节点。</p>
<ul>
<li>在方程的第一部分，在方括号之前，我们有一个额外的嵌套总和，表示输出节点的数量。</li>
<li>在正则化部分，在方括号后面，我们必须考虑多个theta矩阵。当前theta矩阵中的列数等于当前图层中的节点数（包括偏置单元）。在我们当前theta矩阵中的行数等于下一层中的节点数（不包括偏置单元）。与之前的逻辑回归一样，我们对每一项进行平方。</li>
</ul>
<h3 id="1-2误差反向传播"><a href="#1-2误差反向传播" class="headerlink" title="1.2误差反向传播"></a>1.2误差反向传播</h3><p>就像我们在逻辑回归和线性回归中使用梯度下降所做的一样。<br>我们的目标是：$\min_\Theta J(\Theta)$</p>
<p>所以我们希望使用theta中的一组最优参数来最小化我们的成本函数J。寻找最小的参数，需要使用梯度下降法；而梯度下降法最重要的是计算梯度$\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}J(\Theta)$</p>
<p>为了计算这个偏导数，我们使用反向传播算法：<br><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/87838602.jpg" alt=""></p>
<p>我们现在来讲一下反向传播算法，它是<strong>计算偏导数的</strong>一种有效方法。</p>
<ol>
<li>设$a^{(1)} := x^{(t)}$</li>
<li><p>执行前向传播以计算$a^{(l)}$ for l=2,3,…,L<br><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/23499165.jpg" alt=""></p>
</li>
<li><p>使用$y^{(t)}$计算最后一层的误差：$\delta^{(L)} = a^{(L)} - y^{(t)}$</p>
</li>
</ol>
<p>其中L是我们的总层数，a（L）是最后一层激活单元的输出向量。<br>所以我们最后一层的“误差值”就是我们最后一层的实际结果和y中的正确输出的差别。<br>为了得到最后一层之前的图层的增量值，我们可以使用一个从右到左的方程式：</p>
<ol>
<li>计算之前层次的误差：$\delta^{(L-1)}$ , $\delta^{(L-2)}$ ,… ,$\delta^{(2)}$</li>
</ol>
<p>使用公式：$\delta^{(l)} = ((\Theta^{(l)})^T \delta^{(l+1)})\ .<em>\ a^{(l)}\ .</em>\ (1 - a^{(l)})$</p>
<p>其中，我们用一个称为g’的函数或者g-prime来元素乘法，g是用z（l）给出的输入值评估的激活函数g的导数：$g’(z^{(l)}) = a^{(l)}\ .*\ (1 - a^{(l)})$</p>
<ol>
<li>进一步，把每个样本的误差合计$\Delta^{(l)}<em>{i,j} := \Delta^{(l)}</em>{i,j} + a_j^{(l)} \delta_i^{(l+1)}$</li>
</ol>
<p>然后计算正则化:</p>
<ul>
<li>$D^{(l)}<em>{i,j} := \dfrac{1}{m}\left(\Delta^{(l)}</em>{i,j} + \lambda\Theta^{(l)}_{i,j}\right)$</li>
<li>$D^{(l)}<em>{i,j} := \dfrac{1}{m}\Delta^{(l)}</em>{i,j}$</li>
</ul>
<p>误差-增量 矩阵D被用作“累加器”来累加我们的误差，并最终计算得到我们所需要的偏导数：$\frac \partial {\partial \Theta<em>{ij}^{(l)}} J(\Theta)=D</em>{ij}^{(l)}$</p>
<h3 id="1-3直观感受反向传播"><a href="#1-3直观感受反向传播" class="headerlink" title="1.3直观感受反向传播"></a>1.3直观感受反向传播</h3><p>吴老师生怕我们不能“理解感受”反向传播，所以在这一节，他讲了一种反向传播的直观理解方式。</p>
<p>首先回忆神经网络的代价函数是：</p>
<p>$J(\Theta) = - \frac{1}{m} \sum<em>{t=1}^m\sum</em>{k=1}^K \left[ y^{(t)}<em>k \ \log (h</em>\Theta (x^{(t)}))_k + (1 - y^{(t)}<em>k)\ \log (1 - h</em>\Theta(x^{(t)})<em>k)\right] + \frac{\lambda}{2m}\sum</em>{l=1}^{L-1} \sum_{i=1}^{s<em>l} \sum</em>{j=1}^{s<em>l+1} ( \Theta</em>{j,i}^{(l)})^2$</p>
<p>如果我们考虑简单的非多类分类（k = 1）并且忽视正则化，则成本计算如下：</p>
<p>$cost(t) =y^{(t)} \ \log (h<em>\Theta (x^{(t)})) + (1 - y^{(t)})\ \log (1 - h</em>\Theta(x^{(t)}))$</p>
<p>那么直观上，$\delta_j^{(l)}$是$a^{(l)}_j$（第1层中的单元j）的“误差”。<br>更正式地说，δ值实际上是成本函数的导数，即：<br>$\delta_j^{(l)} = \dfrac{\partial}{\partial z_j^{(l)}} cost(t)$</p>
<p><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-1/63003101.jpg" alt=""></p>
<p>每一个神经元的误差都与后面连接的神经元有关。比如：<br>$\delta<em>2^{(2)}=\Theta</em>{12}^{(2)}<em>\delta<em>1^{(3)}+\Theta</em>{22}^{(2)}</em>\delta_2^{(3)}$</p>
<p>再比如：$\delta<em>2^{(3)}=\Theta</em>{12}^{(3)}*\delta_1^{(4)}$</p>
<p>tips：这是一种表达方法，并不意味着使用这么简单的方法就能求出δ。这只是一种解释，直观的展示不同层次误差之间的关系。</p>
<blockquote>
<p>我对反向传播的一种形象的理解： </p>
</blockquote>
<ol>
<li>由于参数选的不好，导致网络最后输出的结果与真实值相差甚远。我们很自然的求出了最后一层的误差（真实-输出）。</li>
<li>但是，最后一层的神经元不服气：明明数值都是前面的神经元传递过来的，出了误差凭什么都赖我啊？我要兴师问罪！</li>
<li>于是，最后一层的神经元就去找前面一层的神经元问罪，问罪的证据就是参数Θ。谁的Θ大，就说明谁传过来的误差大，责任也就越多。靠这个方法，最后一层的神经元，把误差的责任按照比例“推卸”给了前一层。</li>
<li>前一层也按照这个方式，一层层往前“推诿责任”。这样，误差就反向传播给了每一层。</li>
</ol>
<h2 id="2神经网络的技巧"><a href="#2神经网络的技巧" class="headerlink" title="2神经网络的技巧"></a>2神经网络的技巧</h2><h3 id="2-1参数的展开"><a href="#2-1参数的展开" class="headerlink" title="2.1参数的展开"></a>2.1参数的展开</h3><p>使用神经网络时，我们处理的一组矩阵：<br>$\Theta^{(1)},\Theta^{(2)}\Theta^{(3)}…$</p>
<p>为了使用诸如“fminunc（）”这样的优化函数，我们将要“展开”所有元素，并将它们放入一个长向量中，我们可以使用命令[]：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ]</span><br></pre></td></tr></table></figure></p>
<p>如果Theta1的尺寸是10x11，Theta2是10x11，Theta3是1x11，那么我们可以从“展开”版本中取回我们的原始矩阵，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Theta1 = reshape(thetaVector(1:110),10,11)</span><br><span class="line">Theta2 = reshape(thetaVector(111:220),10,11)</span><br><span class="line">Theta3 = reshape(thetaVector(221:231),1,11)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/98417041.jpg" alt=""><br>像这样的函数需要一个参数向量。</p>
<h3 id="2-2梯度检验-Gradient-Checking"><a href="#2-2梯度检验-Gradient-Checking" class="headerlink" title="2.2梯度检验 Gradient Checking"></a>2.2梯度检验 Gradient Checking</h3><p>渐变检查将确保我们的反向传播按预期工作。我们可以用下式近似我们的成本函数的导数：</p>
<p>$\dfrac{\partial}{\partial\Theta}J(\Theta) \approx \dfrac{J(\Theta + \epsilon) - J(\Theta - \epsilon)}{2\epsilon}$</p>
<p>使用多个theta矩阵，我们可以如下近似于关于Θj的导数：<br>$\dfrac{\partial}{\partial\Theta_j}J(\Theta) \approx \dfrac{J(\Theta_1,\Theta_j + \epsilon, \Theta_n) - J(\Theta_1 , \Theta_j - \epsilon,  \Theta_n)}{2\epsilon}$</p>
<p>为保证数学运算正确ε（ε）的一个很小的值，比如ε=${\epsilon = 10^{-4}}$。<br>但如果ε的值太小，我们最终会出现数值问题。</p>
<p>因此，我们只是在Θj矩阵中加上或减去ε。在octave我们可以做到这一点，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">epsilon = 1e-4;</span><br><span class="line">for i = 1:n,</span><br><span class="line">  thetaPlus = theta;</span><br><span class="line">  thetaPlus(i) += epsilon;</span><br><span class="line">  thetaMinus = theta;</span><br><span class="line">  thetaMinus(i) -= epsilon;</span><br><span class="line">  gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon)</span><br><span class="line">end;</span><br></pre></td></tr></table></figure></p>
<p>记住一旦验证了反向传播算法是正确的，就不需要再次计算gradApprox。因为<br>计算gradApprox的代码可能非常慢。</p>
<h3 id="2-3随机初始化参数"><a href="#2-3随机初始化参数" class="headerlink" title="2.3随机初始化参数"></a>2.3随机初始化参数</h3><p>将所有的权重初始化为0不适用于神经网络。那样反向传播时，所有节点将重复更新为相同的值。</p>
<p>相反，我们可以使用以下方法随机初始化我们的Θ矩阵的权重：<br><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/93655022.jpg" alt=""><br>因此，我们将每个$\Theta^{(l)}_{ij}$初始化为[-ε，ε]之间的随机值。使用上面的公式保证我们得到所需的界限。相同的程序适用于所有的Θ。以下是您可以用来进行实验的一些工作代码。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;</span><br><span class="line">Theta2 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;</span><br><span class="line">Theta3 = rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON;</span><br></pre></td></tr></table></figure>
<p>rand（x，y）只是一个八度函数，它将初始化一个0到1之间的随机实数矩阵。</p>
<h3 id="2-4总结神经网络"><a href="#2-4总结神经网络" class="headerlink" title="2.4总结神经网络"></a>2.4总结神经网络</h3><ol>
<li>网络体系结构</li>
</ol>
<p>首先，选择一个网络体系结构;选择你的神经网络的布局，包括每层中有多少个隐藏单元，以及你想要的总共有多少层。一些经验：</p>
<ul>
<li>输入单元的数量=特征的维度x（i）</li>
<li>输出单元的数量=类的数量y</li>
<li>每层隐藏单元的数量=通常越多越好（必须与计算成本平衡，因为随着更多隐藏单元的增加而增加）</li>
<li>默认值：1个隐藏层。如果您有多个隐藏层，则建议您在每个隐藏层中具有相同数量的单元。</li>
</ul>
<ol>
<li>模型的训练</li>
</ol>
<p>模型的训练遵照以下步骤：</p>
<ol>
<li>随机初始化权重</li>
<li>实现向前传播以获得任何x（i）的hΘ（x（i）），</li>
<li>实施成本函数</li>
<li>实施反向传播以计算偏导数<ul>
<li>循环每个训练的例子for i = 1:m</li>
</ul>
</li>
<li>使用梯度检查来确认您的反向传播的作品。然后禁用梯度检查。</li>
<li>使用梯度下降或内置的优化功能，以theta中的权重最小化成本函数。</li>
</ol>
<p>下面的图像让我们直观地了解当我们实施我们的神经网络时发生了什么：</p>
<p><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/48392701.jpg" alt=""></p>
<p>理想情况下，你需要$h_\Theta(x^{(i)})$≈$y^{(i)}$。这将使我们的成本函数最小化。但是，请记住，J（Θ）不是凸的，因此我们可以最终找到局部最小值。</p>
<h2 id="3神经网络的应用"><a href="#3神经网络的应用" class="headerlink" title="3神经网络的应用"></a>3神经网络的应用</h2><p>吴老师举了一个自动驾驶的例子：<br><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/80554627.jpg" alt=""></p>
<p>训练一个人驾驶汽车 然后让ALVINN观看 。<br>ALVINN每两秒  将前方的路况图生成一张数字化图片 并且记录驾驶者的驾驶方向 。<br>得到的训练集图片 被压缩为30x32像素 并且作为输入 提供给ALVINN的三层<br>神经网络。 通过使用反向传播学习算法， ALVINN会训练得到一个 与人类驾驶员操纵方向 基本相近的结果。</p>
<p>一开始 我们的网络选择出的方向是随机的 ，<br>大约经过两分钟的训练后 ，我们的神经网络 便能够准确地模拟 人类驾驶者的<br>驾驶方向 对其他道路类型</p>
<h2 id="4测验quiz"><a href="#4测验quiz" class="headerlink" title="4测验quiz"></a>4测验quiz</h2><ol>
<li><p>You are training a three layer neural network and would like to use backpropagation to compute the gradient of the cost function. In the backpropagation algorithm, one of the steps is to update。答案A<br><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/50567110.jpg" alt=""></p>
</li>
<li><p>Suppose Theta1 is a 5x3 matrix, and Theta2 is a 4x6 matrix. You set thetaVec=[Theta1(:);Theta2(:)]. Which of the following correctly recovers Theta2?答案A<br><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/96288279.jpg" alt=""></p>
</li>
<li><p>Let J(θ)=3θ3+2. Let θ=1, and ϵ=0.01. Use the formula J(θ+ϵ)−J(θ−ϵ)2ϵ to numerically compute an approximation to the derivative at θ=1. What value do you get? (When θ=1, the true/exact derivative is dJ(θ)dθ=9.)答案：A<br><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/47393977.jpg" alt=""></p>
</li>
<li><p>Which of the following statements are true? Check all that apply.答案AD<br><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/96772320.jpg" alt=""></p>
</li>
</ol>
<ol>
<li>Which of the following statements are true? Check all that apply.答案AD</li>
</ol>
<p>If we are training a neural network using gradient descent, one reasonable “debugging” step to make sure it is working is to plot J(Θ) as a function of the number of iterations, and make sure it is decreasing (or at least non-increasing) after each iteration.<br><img src="http://oqy7bjehk.bkt.clouddn.com/17-12-3/83689737.jpg" alt=""></p>
<h2 id="5编程题"><a href="#5编程题" class="headerlink" title="5编程题"></a>5编程题</h2><p>在前面的练习中，你实现了神经网络的前馈传播，并用它来预测我们提供的权重的手写数字。 在这个练习中，您将实施反向传播算法来学习神经网络的参数。 所提供的脚本ex4.m将帮助您逐步完成这个练习。</p>
<ol>
<li>Part 1: Loading and Visualizing Data </li>
</ol>
<p>自动画图，不用修改。</p>
<ol>
<li>Part 2: Loading Parameters</li>
</ol>
<p>自动加载</p>
<ol>
<li>Part 3: Compute Cost (Feedforward)</li>
<li>Part 4: Implement Regularization </li>
</ol>
<p>这两个都是修改nnCostFunction.m</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">%计算每层的结果，记得要把bias unit加上，第一次写把a1 写成了 [ones(m,1); X];  </span><br><span class="line">a1 = [ones(m,1) X];  </span><br><span class="line">z2 = Theta1 * a1&apos;;  </span><br><span class="line">a2 = sigmoid(z2);  </span><br><span class="line">a2 = [ones(1,m); a2]; %这里 a2 和 a1 的格式已经不一样了，a1是行排列，a2是列排列  </span><br><span class="line">z3 = Theta2 * a2;  </span><br><span class="line">a3 = sigmoid(z3);  </span><br><span class="line">  </span><br><span class="line">% 首先把原先label表示的y变成向量模式的output，下面用了循环  </span><br><span class="line">y_vect = zeros(num_labels, m);  </span><br><span class="line">for i = 1:m,  </span><br><span class="line">    y_vect(y(i),i) = 1;  </span><br><span class="line">end;  </span><br><span class="line">  </span><br><span class="line">%每一training example的cost function是使用的向量计算，然后for loop累加所有m个training example  </span><br><span class="line">%的cost function  </span><br><span class="line">for i=1:m,  </span><br><span class="line">    J =J+ sum(-1*y_vect(:,i).*log(a3(:,i))-(1-y_vect(:,i)).*log(1-a3(:,i)));  </span><br><span class="line">end;  </span><br><span class="line">J = J/m;  </span><br><span class="line">  </span><br><span class="line">%增加regularization，一开始只写了一个sum，但其实theta1 2 分别都是矩阵，一个sum只能按列累加，bias unit的theta不参与regularization  </span><br><span class="line">J = J + lambda*(sum(sum(Theta1(:,2:end).^2))+sum(sum(Theta2(:,2:end).^2)))/2/m;  </span><br><span class="line">  </span><br><span class="line">%backward propagation  </span><br><span class="line">%Δ的元素个数应该和对应的theta中的元素的个数相同  </span><br><span class="line">Delta1 = zeros(size(Theta1));  </span><br><span class="line">Delta2 = zeros(size(Theta2));  </span><br><span class="line">for i=1:m,  </span><br><span class="line">    delta3 = a3(:,i) - y_vect(:,i);  </span><br><span class="line">    T=(Theta2&apos;*delta3);</span><br><span class="line">    %注意这里的δ是不包含bias unit的delta的，毕竟bias unit永远是1，  </span><br><span class="line">    %不需要计算delta, 下面的2:end,: 过滤掉了bias unit相关值  </span><br><span class="line">    delta2 = T(2:end,:).*sigmoidGradient(z2(:,i));  </span><br><span class="line">    %移除bias unit上的delta2，但是由于上面sigmoidGradient式子中  </span><br><span class="line">    %的z，本身不包含bias unit，所以下面的过滤不必要，注释掉。  </span><br><span class="line">    %delta2 = delta2(2:end);  </span><br><span class="line">    Delta2 =Delta2+ delta3 *a2(:,i)&apos;;</span><br><span class="line">      </span><br><span class="line">    %第一层的input是一行一行的，和后面的结构不一样，后面是一列作为一个example  </span><br><span class="line">    Delta1 =Delta1+ delta2 * a1(i,:);  </span><br><span class="line">end;  </span><br><span class="line">  </span><br><span class="line">%总结一下，δ不包含bias unit的偏差值，Δ对跟θ对应的，用来计算每个θ  </span><br><span class="line">%后面的偏导数的，所以Δ包含bias unit的θ  </span><br><span class="line">Theta2_grad = Delta2/m;  </span><br><span class="line">Theta1_grad = Delta1/m;  </span><br><span class="line">  </span><br><span class="line">%regularization gradient  </span><br><span class="line">  </span><br><span class="line">Theta2_grad(:,2:end) = Theta2_grad(:,2:end) + lambda * Theta2(:,2:end) / m;  </span><br><span class="line">Theta1_grad(:,2:end) = Theta1_grad(:,2:end) + lambda * Theta1(:,2:end) / m;</span><br></pre></td></tr></table></figure>
<ol>
<li>Part 5: Sigmoid Gradient</li>
</ol>
<p>在开始实施神经网络之前，您将首先实现sigmoid函数的渐变。 您应该完成sigmoidGradient.m文件中的代码。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g = 1.0 ./ (1.0 + exp(-z));</span><br></pre></td></tr></table></figure>
<ol>
<li>Part 6: Initializing Pameters</li>
</ol>
<p>在这部分的练习中，你将开始实现分类数字的双层神经网络。 您将开始执行一个函数来初始化神经网络的权重（randInitializeWeights.m）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">epsilon = 0.12;</span><br><span class="line">W = rand(L_out, 1+L_in)*2*epsilon - epsilon;</span><br></pre></td></tr></table></figure>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="http://yoursite.com/2017/12/03/coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播/" data-id="cjcrgkd8a001u7xje7c5tr6de" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="http://yoursite.com/2017/12/03/coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="http://yoursite.com/2017/12/03/coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播/">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2017/12/14/coursera-斯坦福-机器学习-吴恩达-第6周笔记-算法改进and机器学习系统设计/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    coursera-斯坦福-机器学习-吴恩达-第6周笔记-算法改进and机器学习系统设计
                
            </div>
        </a>
    
    
        <a href="/2017/11/30/coursera-斯坦福-机器学习-吴恩达-第4周笔记-神经网络/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">coursera-斯坦福-机器学习-吴恩达-第4周笔记-神经网络</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
</section>
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/01/18/零基础学习GitHub桌面版-6使用pages创建网站/" class="thumbnail">
    
    
        <span style="background-image:url(http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/china-great-wall.jpg)" alt="零基础学习GitHub桌面版-6使用pages创建网站" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Git/">Git</a></p>
                            <p class="item-title"><a href="/2018/01/18/零基础学习GitHub桌面版-6使用pages创建网站/" class="title">零基础学习GitHub桌面版-6使用pages创建网站</a></p>
                            <p class="item-date"><time datetime="2018-01-18T14:07:04.000Z" itemprop="datePublished">2018-01-18</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/01/10/coursera-斯坦福-机器学习-吴恩达-机器学习课程总结/" class="thumbnail">
    
    
        <span style="background-image:url(http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/math.jpg)" alt="coursera-斯坦福-机器学习-吴恩达-机器学习课程总结" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/机器学习/">机器学习</a></p>
                            <p class="item-title"><a href="/2018/01/10/coursera-斯坦福-机器学习-吴恩达-机器学习课程总结/" class="title">coursera-斯坦福-机器学习-吴恩达-机器学习课程总结</a></p>
                            <p class="item-date"><time datetime="2018-01-09T18:32:54.000Z" itemprop="datePublished">2018-01-10</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/01/09/coursera-斯坦福-机器学习-吴恩达-第11周笔记-ORC系统/" class="thumbnail">
    
    
        <span style="background-image:url(http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/salt-lake.jpg)" alt="coursera-斯坦福-机器学习-吴恩达-第11周笔记-ORC系统" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/机器学习/">机器学习</a></p>
                            <p class="item-title"><a href="/2018/01/09/coursera-斯坦福-机器学习-吴恩达-第11周笔记-ORC系统/" class="title">coursera-斯坦福-机器学习-吴恩达-第11周笔记-ORC系统</a></p>
                            <p class="item-date"><time datetime="2018-01-09T14:32:54.000Z" itemprop="datePublished">2018-01-09</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/01/08/人工智能工程师学习路线 自然语言处理算法工程师学习路径/" class="thumbnail">
    
    
        <span style="background-image:url(http://blog.zhangruipeng.me/hexo-theme-icarus/gallery/shoes.jpg)" alt="人工智能工程师学习路线 自然语言处理算法工程师学习路径" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/自然语言处理/">自然语言处理</a></p>
                            <p class="item-title"><a href="/2018/01/08/人工智能工程师学习路线 自然语言处理算法工程师学习路径/" class="title">人工智能工程师学习路线 自然语言处理算法工程师学习路径</a></p>
                            <p class="item-date"><time datetime="2018-01-08T03:39:54.000Z" itemprop="datePublished">2018-01-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/01/07/coursera-斯坦福-机器学习-吴恩达-第10周笔记-使用大数据训练/" class="thumbnail">
    
    
        <span style="background-image:url(http://img3.cache.netease.com/photo/0003/2009-05-05/58IOGNQF0BOd0003.jpg)" alt="coursera-斯坦福-机器学习-吴恩达-第10周笔记-使用大数据训练" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/机器学习/">机器学习</a></p>
                            <p class="item-title"><a href="/2018/01/07/coursera-斯坦福-机器学习-吴恩达-第10周笔记-使用大数据训练/" class="title">coursera-斯坦福-机器学习-吴恩达-第10周笔记-使用大数据训练</a></p>
                            <p class="item-date"><time datetime="2018-01-07T03:32:54.000Z" itemprop="datePublished">2018-01-07</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/自然语言处理/">自然语言处理</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/驱动开发/">驱动开发</a><span class="category-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">一月 2015</a><span class="archive-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Anaconda/">Anaconda</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/">CNN</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DevOps/">DevOps</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DriverSttudio3-2/">DriverSttudio3.2</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Editplus/">Editplus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GBK/">GBK</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/">Git</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GitHub/">GitHub</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keras/">Keras</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Oracle/">Oracle</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pycharm/">Pycharm</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">21</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/">RNN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorboard/">Tensorboard</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/">Tensorflow</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/USB/">USB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/UTF-8/">UTF-8</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/coursera/">coursera</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ddk/">ddk</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/eclipse/">eclipse</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jieba/">jieba</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/maven/">maven</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/myeclipse/">myeclipse</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrapy/">scrapy</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/win7/">win7</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/word2vec/">word2vec</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分词/">分词</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/学习路线/">学习路线</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/报错/">报错</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文件操作/">文件操作</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/汽车之家/">汽车之家</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编码/">编码</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/自然语言处理/">自然语言处理</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/运维/">运维</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面向对象/">面向对象</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/驱动程序/">驱动程序</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Anaconda/" style="font-size: 13.33px;">Anaconda</a> <a href="/tags/CNN/" style="font-size: 11.11px;">CNN</a> <a href="/tags/DevOps/" style="font-size: 10px;">DevOps</a> <a href="/tags/DriverSttudio3-2/" style="font-size: 10px;">DriverSttudio3.2</a> <a href="/tags/Editplus/" style="font-size: 10px;">Editplus</a> <a href="/tags/GBK/" style="font-size: 11.11px;">GBK</a> <a href="/tags/Git/" style="font-size: 17.78px;">Git</a> <a href="/tags/GitHub/" style="font-size: 17.78px;">GitHub</a> <a href="/tags/Java/" style="font-size: 17.78px;">Java</a> <a href="/tags/Keras/" style="font-size: 10px;">Keras</a> <a href="/tags/Linux/" style="font-size: 13.33px;">Linux</a> <a href="/tags/Oracle/" style="font-size: 10px;">Oracle</a> <a href="/tags/Pycharm/" style="font-size: 12.22px;">Pycharm</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/Tensorboard/" style="font-size: 10px;">Tensorboard</a> <a href="/tags/Tensorflow/" style="font-size: 15.56px;">Tensorflow</a> <a href="/tags/USB/" style="font-size: 10px;">USB</a> <a href="/tags/UTF-8/" style="font-size: 11.11px;">UTF-8</a> <a href="/tags/coursera/" style="font-size: 18.89px;">coursera</a> <a href="/tags/ddk/" style="font-size: 10px;">ddk</a> <a href="/tags/eclipse/" style="font-size: 14.44px;">eclipse</a> <a href="/tags/jieba/" style="font-size: 10px;">jieba</a> <a href="/tags/maven/" style="font-size: 10px;">maven</a> <a href="/tags/myeclipse/" style="font-size: 12.22px;">myeclipse</a> <a href="/tags/scrapy/" style="font-size: 14.44px;">scrapy</a> <a href="/tags/win7/" style="font-size: 10px;">win7</a> <a href="/tags/word2vec/" style="font-size: 10px;">word2vec</a> <a href="/tags/分词/" style="font-size: 10px;">分词</a> <a href="/tags/学习路线/" style="font-size: 12.22px;">学习路线</a> <a href="/tags/报错/" style="font-size: 16.67px;">报错</a> <a href="/tags/文件操作/" style="font-size: 10px;">文件操作</a> <a href="/tags/机器学习/" style="font-size: 18.89px;">机器学习</a> <a href="/tags/汽车之家/" style="font-size: 11.11px;">汽车之家</a> <a href="/tags/深度学习/" style="font-size: 16.67px;">深度学习</a> <a href="/tags/爬虫/" style="font-size: 17.78px;">爬虫</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/自然语言处理/" style="font-size: 17.78px;">自然语言处理</a> <a href="/tags/运维/" style="font-size: 10px;">运维</a> <a href="/tags/面向对象/" style="font-size: 10px;">面向对象</a> <a href="/tags/驱动程序/" style="font-size: 10px;">驱动程序</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2018 Qingtang<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>



        
    
    <script>
    var disqus_config = function () {
        
            this.page.url = 'http://yoursite.com/2017/12/03/coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播/';
        
        this.page.identifier = 'coursera-斯坦福-机器学习-吴恩达-第5周笔记-反向传播';
    };
    (function() { 
        var d = document, s = d.createElement('script');  
        s.src = '//' + 'xqtbox' + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>